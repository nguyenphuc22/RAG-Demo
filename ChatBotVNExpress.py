import streamlit as st
import pymongo
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random

# Streamlit interface for API keys and connection string
st.sidebar.title("Configuration")
gemini_api_key = st.sidebar.text_input("Gemini API Key", type="password")
mongo_connection_string = st.sidebar.text_input("MongoDB Connection String", type="password")

class VnExpressExcelCrawler:
    def __init__(self, base_url='https://vnexpress.net/'):
        self.base_url = base_url
        self.articles = []

    def get_page_content(self, url):
        try:
            response = requests.get(url)
            response.raise_for_status()
            return response.text
        except requests.RequestException as e:
            print(f"Error fetching {url}: {e}")
            return None

    def parse_articles(self, html_content):
        soup = BeautifulSoup(html_content, 'html.parser')
        for article in soup.find_all('article', class_='item-news'):
            title_element = article.find('h3', class_='title-news')
            if title_element and title_element.a:
                title = title_element.a.text.strip()
                url = title_element.a['href']
                description = article.find('p', class_='description')
                description = description.text.strip() if description else ""
                self.articles.append({
                    'title': title,
                    'url': url,
                    'description': description
                })

    def crawl(self, max_articles=50, delay_range=(1, 3)):
        html_content = self.get_page_content(self.base_url)
        if not html_content:
            return

        self.parse_articles(html_content)

        while len(self.articles) < max_articles:
            time.sleep(random.uniform(*delay_range))
            next_page = self.find_next_page(html_content)
            if not next_page:
                break
            html_content = self.get_page_content(next_page)
            if not html_content:
                break
            self.parse_articles(html_content)

        self.articles = self.articles[:max_articles]

    def find_next_page(self, html_content):
        soup = BeautifulSoup(html_content, 'html.parser')
        next_page_link = soup.find('a', class_='next-page')
        return next_page_link['href'] if next_page_link else None

    def save_to_excel(self, filename='vnexpress_articles.xlsx'):
        df = pd.DataFrame(self.articles)
        df.to_excel(filename, index=False)
        print(f"Saved {len(self.articles)} articles to {filename}")


# MongoDB connection
@st.cache_resource
def init_mongodb_connection(connection_string):
    if not connection_string:
        st.error("Please provide a MongoDB connection string.")
        return None
    try:
        client = pymongo.MongoClient(connection_string)
        client.admin.command('ping')
        st.sidebar.success("Successfully connected to MongoDB!")
        return client
    except Exception as e:
        st.sidebar.error(f"Failed to connect to MongoDB: {e}")
        return None

client = init_mongodb_connection(mongo_connection_string)

if client:
    db = client["sample_mflix"]
    collection = db['vnexpress_articles']

    print(f"Number of documents in collection: {collection.count_documents({})}")
    print("Indexes:", collection.index_information())

    # Load the embedding model
    @st.cache_resource
    def load_embedding_model():
        return SentenceTransformer("sentence-transformers/all-MiniLM-L12-v2")

    embedding_model = load_embedding_model()

    # Gemini setup
    if gemini_api_key:
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('gemini-1.5-pro')
    else:
        st.error("Please provide a Gemini API key.")
        st.stop()

    def get_embedding(text: str) -> list[float]:
        if not text.strip():
            print("Attempted to get embedding for empty text.")
            return []
        embedding = embedding_model.encode(text)
        return embedding.tolist()

    def vector_search(user_query, collection, limit=4):
        query_embedding = get_embedding(user_query)
        if not query_embedding:
            return "Invalid query or embedding generation failed."

        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }

        unset_stage = {"$unset": "embedding"}

        project_stage = {
            "$project": {
                "_id": 0,
                "title": 1,
                "url": 1,
                "description": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }

        pipeline = [vector_search_stage, unset_stage, project_stage]
        results = collection.aggregate(pipeline)
        return list(results)


    if st.sidebar.button("Crawl New Articles"):
        crawler = VnExpressExcelCrawler()
        with st.spinner('Crawling new articles...'):
            crawler.crawl(max_articles=20)  # Crawl 20 b√†i vi·∫øt m·ªõi
            crawler.save_to_excel()
        st.sidebar.success("Crawling completed!")

    def get_search_result(query, collection):
        get_knowledge = vector_search(query, collection, 5)
        print("get_knowledge")
        print(get_knowledge)
        search_result = ""
        for i, result in enumerate(get_knowledge, 1):
            search_result += f"\n{i}) Title: {result.get('title', 'N/A')}"
            search_result += f"\nURL: {result.get('url', 'N/A')}"
            search_result += f"\nDescription: {result.get('description', 'N/A')[:200]}..."
            search_result += "\n\n"
        return search_result

    st.title("üí¨ VnExpress RAG Chatbot")
    st.caption("üöÄ A Streamlit chatbot powered by Gemini and MongoDB, using VnExpress articles")

    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n v·ªÅ c√°c tin t·ª©c t·ª´ VnExpress?"}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        source_information = get_search_result(prompt.lower(), collection)
        combined_prompt = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω AI ƒë∆∞·ª£c ƒë√†o t·∫°o ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi d·ª±a tr√™n c√°c b√†i b√°o t·ª´ VnExpress. 
        C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {prompt}
        H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin sau t·ª´ c√°c b√†i b√°o li√™n quan: 
        {source_information}
        N·∫øu th√¥ng tin kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi, h√£y n√≥i r·∫±ng b·∫°n kh√¥ng c√≥ ƒë·ªß th√¥ng tin v√† ƒë·ªÅ ngh·ªã ng∆∞·ªùi d√πng ƒë·∫∑t c√¢u h·ªèi kh√°c ho·∫∑c cung c·∫•p th√™m ng·ªØ c·∫£nh.
        Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v√† gi·ªØ gi·ªçng ƒëi·ªáu th√¢n thi·ªán, chuy√™n nghi·ªáp."""
        print(combined_prompt)

        response = model.generate_content(combined_prompt)
        msg = response.text
        st.session_state.messages.append({"role": "assistant", "content": msg})
        st.chat_message("assistant").write(msg)

    st.sidebar.title("Gi·ªõi thi·ªáu")
    st.sidebar.info("Chatbot n√†y s·ª≠ d·ª•ng RAG v·ªõi MongoDB v√† Gemini ƒë·ªÉ cung c·∫•p th√¥ng tin t·ª´ c√°c b√†i b√°o VnExpress.")
else:
    st.error("Please configure MongoDB connection to continue.")