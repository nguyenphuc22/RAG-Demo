import streamlit as st
import pymongo
import google.generativeai as genai
from sentence_transformers import SentenceTransformer

# Streamlit interface for API keys and connection string
st.sidebar.title("Configuration")
gemini_api_key = st.sidebar.text_input("Gemini API Key", type="password")
mongo_connection_string = st.sidebar.text_input("MongoDB Connection String", type="password")

# MongoDB connection
@st.cache_resource
def init_mongodb_connection(connection_string):
    if not connection_string:
        st.error("Please provide a MongoDB connection string.")
        return None
    try:
        client = pymongo.MongoClient(connection_string)
        client.admin.command('ping')
        st.sidebar.success("Successfully connected to MongoDB!")
        return client
    except Exception as e:
        st.sidebar.error(f"Failed to connect to MongoDB: {e}")
        return None

client = init_mongodb_connection(mongo_connection_string)

if client:
    db = client["sample_mflix"]
    collection = db['vnexpress_articles']

    print(f"Number of documents in collection: {collection.count_documents({})}")
    print("Indexes:", collection.index_information())

    # Load the embedding model
    @st.cache_resource
    def load_embedding_model():
        return SentenceTransformer("sentence-transformers/all-MiniLM-L12-v2")

    embedding_model = load_embedding_model()

    # Gemini setup
    if gemini_api_key:
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('gemini-1.5-pro')
    else:
        st.error("Please provide a Gemini API key.")
        st.stop()

    def get_embedding(text: str) -> list[float]:
        if not text.strip():
            print("Attempted to get embedding for empty text.")
            return []
        embedding = embedding_model.encode(text)
        return embedding.tolist()

    def vector_search(user_query, collection, limit=4):
        query_embedding = get_embedding(user_query)
        if not query_embedding:
            return "Invalid query or embedding generation failed."

        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }

        unset_stage = {"$unset": "embedding"}

        project_stage = {
            "$project": {
                "_id": 0,
                "title": 1,
                "url": 1,
                "description": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }

        pipeline = [vector_search_stage, unset_stage, project_stage]
        results = collection.aggregate(pipeline)
        return list(results)

    def get_search_result(query, collection):
        get_knowledge = vector_search(query, collection, 5)
        print("get_knowledge")
        print(get_knowledge)
        search_result = ""
        for i, result in enumerate(get_knowledge, 1):
            search_result += f"\n{i}) Title: {result.get('title', 'N/A')}"
            search_result += f"\nURL: {result.get('url', 'N/A')}"
            search_result += f"\nDescription: {result.get('description', 'N/A')[:200]}..."  # Limit description length
            search_result += "\n\n"
        return search_result

    st.title("ğŸ’¬ VnExpress RAG Chatbot")
    st.caption("ğŸš€ A Streamlit chatbot powered by Gemini and MongoDB, using VnExpress articles")

    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n vá» cÃ¡c tin tá»©c tá»« VnExpress?"}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        source_information = get_search_result(prompt.lower(), collection)
        combined_prompt = f"""Báº¡n lÃ  má»™t trá»£ lÃ½ AI Ä‘Æ°á»£c Ä‘Ã o táº¡o Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i dá»±a trÃªn cÃ¡c bÃ i bÃ¡o tá»« VnExpress. 
        CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {prompt}
        HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin sau tá»« cÃ¡c bÃ i bÃ¡o liÃªn quan: 
        {source_information}
        Náº¿u thÃ´ng tin khÃ´ng Ä‘á»§ Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i, hÃ£y nÃ³i ráº±ng báº¡n khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin vÃ  Ä‘á» nghá»‹ ngÆ°á»i dÃ¹ng Ä‘áº·t cÃ¢u há»i khÃ¡c hoáº·c cung cáº¥p thÃªm ngá»¯ cáº£nh.
        LuÃ´n tráº£ lá»i báº±ng tiáº¿ng Viá»‡t vÃ  giá»¯ giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p."""
        print(combined_prompt)

        response = model.generate_content(combined_prompt)
        msg = response.text
        st.session_state.messages.append({"role": "assistant", "content": msg})
        st.chat_message("assistant").write(msg)

    st.sidebar.title("Giá»›i thiá»‡u")
    st.sidebar.info("Chatbot nÃ y sá»­ dá»¥ng RAG vá»›i MongoDB vÃ  Gemini Ä‘á»ƒ cung cáº¥p thÃ´ng tin tá»« cÃ¡c bÃ i bÃ¡o VnExpress.")
else:
    st.error("Please configure MongoDB connection to continue.")