import streamlit as st
import google.generativeai as genai
from data.mongodb_client import init_mongodb_connection, get_collection
from database.NewsCrawlerInterface import NewsCrawlerInterface
from database.baophapluat import BaoPhapLuatExcelCrawler
from database.dantri import DanTriExcelCrawler
from database.thanhnien_crawler import ThanhNienExcelCrawler
from database.thuvienphapluat import ThuVienPhapLuatExcelCrawler
from database.tuoitre_crawler import TuoiTreExcelCrawler
from database.vnexpress_crawler import VnExpressExcelCrawler
from database.vtv_crawler import VTVExcelCrawler
from embedding.embedding_model import load_embedding_model
from prompts.history import update_prompt_with_history
from prompts.prompt import CHATBOT_PROMPT
from evalution.question import evaluation
from search.vector_search import get_search_result, create_vector_and_update_mongodb, preprocess_text
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# Streamlit interface for API keys and connection string
st.sidebar.title("Configuration")
gemini_api_key = st.sidebar.text_input("Gemini API Key", type="password")
mongo_connection_string = st.sidebar.text_input("MongoDB Connection String", type="password")
max_articles = st.sidebar.number_input("Maximum number of articles to crawl", min_value=1, max_value=100, value=20)
client = init_mongodb_connection(mongo_connection_string)
db_name = "sample_mflix"
collection_name = "minh_articles"

crawler_options = {
    # "VnExpress": VnExpressExcelCrawler,
    "Tu·ªïi Tr·∫ª": TuoiTreExcelCrawler,
    "Thanh Ni√™n": ThanhNienExcelCrawler,
    "D√¢n Tr√≠": DanTriExcelCrawler,
    # "B√°o Ph√°p Lu·∫≠t": BaoPhapLuatExcelCrawler,
    # "Th∆∞ Vi·ªán Ph√°p Lu·∫≠t": ThuVienPhapLuatExcelCrawler,
    "VTV": VTVExcelCrawler
}

safety_settings = {
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

selected_crawler = st.sidebar.selectbox("Select Crawler", list(crawler_options.keys()))
if 'show_form' not in st.session_state:
    st.session_state.show_form = False


def get_context_aware_query(current_query):
    if len(st.session_state.messages) < 2:
        return current_query

    previous_query = st.session_state.messages[-2]["content"] if st.session_state.messages[-2]["role"] == "user" else ""
    previous_response = st.session_state.messages[-1]["content"] if st.session_state.messages[-1][
                                                                        "role"] == "assistant" else ""

    context_aware_query = f"""
    D·ª±a tr√™n cu·ªôc h·ªôi tho·∫°i sau:
    C√¢u h·ªèi tr∆∞·ªõc: {previous_query}
    C√¢u tr·∫£ l·ªùi tr∆∞·ªõc: {previous_response}
    C√¢u h·ªèi hi·ªán t·∫°i: {current_query}

    H√£y t·∫°o ra m·ªôt c√¢u h·ªèi m·ªõi k·∫øt h·ª£p ng·ªØ c·∫£nh t·ª´ c√¢u h·ªèi tr∆∞·ªõc v√† c√¢u h·ªèi hi·ªán t·∫°i ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin li√™n quan.
    Ch·ªâ ƒë∆∞a ra c√¢u h·ªèi m·ªõi, kh√¥ng c·∫ßn gi·∫£i th√≠ch g√¨ th√™m.
    """

    try:
        response = model.generate_content(context_aware_query)
        return response.text.strip()
    except Exception as e:
        print(f"L·ªói khi t·∫°o c√¢u h·ªèi c√≥ ng·ªØ c·∫£nh: {str(e)}")
        return current_query


def crawl_and_update(crawler: NewsCrawlerInterface, max_articles: int):
    with st.spinner(f'Crawling up to {max_articles} new articles...'):
        crawler.crawl(max_articles=max_articles)
        df = crawler.save_to_excel("articles.xlsx")
    st.sidebar.success("Crawling completed!")

    with st.spinner('Creating vector embeddings and updating MongoDB...'):
        collection.delete_many({})
        print("All documents deleted from the collection.")
        create_vector_and_update_mongodb(df, collection)


def get_latest_articles(collection, limit=3):
    """L·∫•y c√°c b√†i vi·∫øt m·ªõi nh·∫•t t·ª´ c∆° s·ªü d·ªØ li·ªáu."""
    latest_articles = list(collection.find().sort("date", -1).limit(limit))
    return latest_articles


def generate_question_suggestions(model, articles, conversation_history):
    """T·∫°o g·ª£i √Ω c√¢u h·ªèi d·ª±a tr√™n c√°c b√†i vi·∫øt m·ªõi nh·∫•t v√† l·ªãch s·ª≠ tr√≤ chuy·ªán."""
    if conversation_history.strip():
        context = f"""
        D·ª±a tr√™n l·ªãch s·ª≠ tr√≤ chuy·ªán sau ƒë√¢y, h√£y ƒë·ªÅ xu·∫•t 3 c√¢u h·ªèi m√† ng∆∞·ªùi d√πng c√≥ th·ªÉ quan t√¢m:

        L·ªãch s·ª≠ tr√≤ chuy·ªán:
        {conversation_history}

        H√£y ƒë∆∞a ra 3 c√¢u h·ªèi g·ª£i √Ω li√™n quan ƒë·∫øn cu·ªôc tr√≤ chuy·ªán hi·ªán t·∫°i. Ch·ªâ li·ªát k√™ c√°c c√¢u h·ªèi, kh√¥ng c·∫ßn th√™m gi·∫£i th√≠ch hay ƒë·ªãnh d·∫°ng kh√°c.
        """
    else:
        context = f"""
        D·ª±a tr√™n c√°c b√†i vi·∫øt m·ªõi nh·∫•t sau ƒë√¢y, h√£y ƒë·ªÅ xu·∫•t 3 c√¢u h·ªèi m√† ng∆∞·ªùi d√πng c√≥ th·ªÉ quan t√¢m:

        C√°c b√†i vi·∫øt m·ªõi nh·∫•t:
        {', '.join([article['title'] for article in articles])}

        H√£y ƒë∆∞a ra 3 c√¢u h·ªèi g·ª£i √Ω li√™n quan ƒë·∫øn c√°c ch·ªß ƒë·ªÅ trong c√°c b√†i vi·∫øt m·ªõi. Ch·ªâ li·ªát k√™ c√°c c√¢u h·ªèi, kh√¥ng c·∫ßn th√™m gi·∫£i th√≠ch hay ƒë·ªãnh d·∫°ng kh√°c.
        """

    try:
        response = model.generate_content(context, safety_settings=safety_settings)
        suggestions = response.text.strip().split('\n')
        return suggestions[:3]  # ƒê·∫£m b·∫£o ch·ªâ tr·∫£ v·ªÅ t·ªëi ƒëa 3 g·ª£i √Ω
    except Exception as e:
        print(f"L·ªói khi t·∫°o g·ª£i √Ω c√¢u h·ªèi: {str(e)}")
        return []


def process_user_input(user_input, model, collection):
    print(f"Processing user input: {user_input}")  # Debug print
    st.session_state.messages.append({"role": "user", "content": user_input})

    context_aware_query = get_context_aware_query(user_input)
    preprocessed_prompt = preprocess_text(context_aware_query)

    source_information = get_search_result(preprocessed_prompt, collection)
    combined_prompt = update_prompt_with_history(CHATBOT_PROMPT, user_input, source_information)
    print(f"Context-aware query: {context_aware_query}")
    print(combined_prompt)

    try:
        response = model.generate_content(combined_prompt, safety_settings=safety_settings)
        msg = response.text
    except Exception as e:
        msg = f"Xin l·ªói, ƒë√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n: {str(e)}"

    st.session_state.messages.append({"role": "assistant", "content": msg})

def handle_suggestion_click(suggestion):
    st.session_state.selected_question = suggestion
    st.rerun()

if client:
    collection = get_collection(client, db_name, collection_name)
    print(f"Number of documents in collection: {collection.count_documents({})}")
    print("Indexes:", collection.index_information())
    embedding_model = load_embedding_model()

    # Gemini setup
    if gemini_api_key:
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
    else:
        st.error("Please provide a valid Gemini API key.")
        st.stop()

    if st.sidebar.button("Crawl New Articles"):
        print("Crawling new articles...")
        crawler_class = crawler_options[selected_crawler]
        crawler = crawler_class()
        crawl_and_update(crawler, max_articles)
    
    if st.sidebar.button("Show/Hide Evaluate"):
        st.session_state.show_form = not st.session_state.show_form 

    evaluation(collection, model)
    st.title("üí¨ Improved Hybrid Search RAG Chatbot")
    st.caption(
        "üöÄ A Streamlit chatbot powered by Gemini and MongoDB, using Enhanced Hybrid Search with Semantic Reranking")

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant",
                                      "content": "Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n v·ªÅ c√°c tin t·ª©c t·ª´ c√°c ngu·ªìn tin t·ª©c Vi·ªát Nam?"}]

    if "selected_question" not in st.session_state:
        st.session_state.selected_question = None

    # X·ª≠ l√Ω c√¢u h·ªèi ƒë√£ ch·ªçn t·ª´ l·∫ßn ch·∫°y tr∆∞·ªõc
    if st.session_state.selected_question:
        process_user_input(st.session_state.selected_question, model, collection)
        st.session_state.selected_question = None  # Reset sau khi x·ª≠ l√Ω

    # Hi·ªÉn th·ªã t·∫•t c·∫£ tin nh·∫Øn
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # Th√™m ph·∫ßn g·ª£i √Ω c√¢u h·ªèi
    latest_articles = get_latest_articles(collection)
    conversation_history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages[-5:]])
    question_suggestions = generate_question_suggestions(model, latest_articles, conversation_history)

    if question_suggestions:
        st.sidebar.subheader("G·ª£i √Ω c√¢u h·ªèi:")
        for i, suggestion in enumerate(question_suggestions):
            print(f"Suggestion {i + 1}: {suggestion}")
            st.sidebar.button(suggestion, key=f"suggestion_{i}", on_click=handle_suggestion_click, args=(suggestion,))


    if prompt := st.chat_input():
        process_user_input(prompt, model, collection)
        st.rerun()

    st.sidebar.title("Gi·ªõi thi·ªáu")
    st.sidebar.info(
        "Chatbot n√†y s·ª≠ d·ª•ng Hybrid Search c·∫£i ti·∫øn v·ªõi Semantic Reranking, MongoDB v√† Gemini ƒë·ªÉ cung c·∫•p th√¥ng tin t·ª´ c√°c b√†i b√°o t·ª´ nhi·ªÅu ngu·ªìn tin t·ª©c Vi·ªát Nam.")

else:
    st.error("Please configure MongoDB connection to continue.")